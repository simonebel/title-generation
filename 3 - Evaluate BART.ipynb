{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eW63f8h163q5"
   },
   "source": [
    "# 0 - Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 2011,
     "status": "ok",
     "timestamp": 1631702270602,
     "user": {
      "displayName": "Simon Ebel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjk20RS8gkw1uAaPoheFBQw5r-OAvxMeX8qh0REkg=s64",
      "userId": "15738812401286177053"
     },
     "user_tz": -120
    },
    "id": "NQQsXS3y3zpl",
    "outputId": "dc1924a1-e493-45f4-caa7-308c11489a20"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "\n",
    "from seq2seq import plot_loss\n",
    "from bart import BartLayer, generate_data_loader, train, evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5hQzDu5RsQ2n"
   },
   "source": [
    "# 1 - Train Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 18129,
     "status": "ok",
     "timestamp": 1631702288724,
     "user": {
      "displayName": "Simon Ebel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjk20RS8gkw1uAaPoheFBQw5r-OAvxMeX8qh0REkg=s64",
      "userId": "15738812401286177053"
     },
     "user_tz": -120
    },
    "id": "QUpGXiph7lYJ",
    "outputId": "7629677a-e771-4f7d-ffb8-4ec8203a90dc",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 2021\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "root_path = ''\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else : \n",
    "    device = torch.device('cpu')\n",
    "model = BartLayer('sshleifer/distilbart-xsum-12-3').to(device)\n",
    "\n",
    "tokenizer = BartTokenizerFast.from_pretrained('sshleifer/distilbart-xsum-12-3')\n",
    "batch_size = 1\n",
    "train_dataset, train_data_loader, dev_dataset, dev_data_loader, test_dataset, test_data_loader = generate_data_loader(batch_size,\n",
    "                                                                                                                      root_path + './data/preprocess/train.pkl', \n",
    "                                                                                                                      root_path + './data/preprocess/dev.pkl',\n",
    "                                                                                                                      root_path + './data/preprocess/test.pkl', \n",
    "                                                                                                                      tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 628157,
     "status": "error",
     "timestamp": 1631702916870,
     "user": {
      "displayName": "Simon Ebel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjk20RS8gkw1uAaPoheFBQw5r-OAvxMeX8qh0REkg=s64",
      "userId": "15738812401286177053"
     },
     "user_tz": -120
    },
    "id": "CM8-x3xKrXxw",
    "outputId": "cf668274-8f77-4060-a327-80876b2b6a54",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ \n",
      " Eopchs 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 4.00 GiB total capacity; 1.33 GiB already allocated; 7.52 MiB free; 1.33 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-6baf26d33dec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccumulation_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mdev_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdev_bleu\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdev_data_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Machine-Learning\\title-generation\\bart\\train_evaluate.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, device, batch_size, accumulation_steps, train_dataset, train_data_loader, optimizer)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource_att_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcurrent_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0maccumulation_steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mcurrent_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0maccumulation_steps\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 4.00 GiB total capacity; 1.33 GiB already allocated; 7.52 MiB free; 1.33 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "epochs = 8\n",
    "accumulation_steps = 30\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-05, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
    "# scheduler = \n",
    "\n",
    "train_loss_set = []\n",
    "dev_loss_set = []\n",
    "dev_bleu_set = []\n",
    "for epoch in range(epochs) : \n",
    "    print(f'------------------------ \\n Eopchs {epoch}')\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, device, batch_size, accumulation_steps, train_dataset, train_data_loader, optimizer)\n",
    "    dev_loss, dev_bleu  = evaluate(model, device, dev_data_loader, tokenizer)\n",
    "\n",
    "    train_loss_set.append(train_loss)\n",
    "    dev_loss_set.append(dev_loss)\n",
    "    dev_bleu_set.append(dev_bleu)\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f'Epoch took : {end_time-start_time}')\n",
    "plot_loss(train_loss_set, dev_loss_set, dev_bleu_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOO+04MKRYjD3wOo00Gp1Zl",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "BART",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
